version: '3.8'

services:
  # Backend API Service
  backend:
    build:
      context: .
      dockerfile: api/Dockerfile
    container_name: hypergraphrag-api
    ports:
      - "3401:3401"
    environment:
      # OpenAI API Configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1}
      - LLM_MODEL=${LLM_MODEL:-gpt-4o-mini}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-text-embedding-3-small}
      
      # Application Configuration
      - WORKING_DIR=/data/hypergraphrag
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
      
      # CORS Configuration
      - CORS_ORIGINS=${CORS_ORIGINS:-http://localhost:3400,http://localhost:80}
    volumes:
      # Mount data directory for persistent storage
      - ./expr/example:/data/hypergraphrag:ro
      # Mount logs directory
      - ./logs:/app/logs
    networks:
      - hypergraphrag-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:3401/api/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Frontend Web UI Service
  frontend:
    build:
      context: ./web_ui
      dockerfile: Dockerfile
    container_name: hypergraphrag-web
    ports:
      - "80:80"
    environment:
      - VITE_API_BASE_URL=http://localhost:3401
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - hypergraphrag-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 5s

networks:
  hypergraphrag-network:
    driver: bridge

volumes:
  logs:
    driver: local
